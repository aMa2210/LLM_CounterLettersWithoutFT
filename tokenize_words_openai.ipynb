{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved to: test_words_tokenized_by_gpt-4-mini.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import tiktoken\n",
    "\n",
    "# Load the tokenizer for GPT-4\n",
    "model_name = \"gpt-4o-mini\"  # Model name\n",
    "enc = tiktoken.encoding_for_model(model_name)\n",
    "\n",
    "# Function to tokenize words and retrieve separated tokens and token count\n",
    "def tokenize_word(word):\n",
    "    token_ids = enc.encode(word)\n",
    "    subwords = [enc.decode([token_id]) for token_id in token_ids]\n",
    "    num_tokens = len(subwords)\n",
    "    return num_tokens, subwords\n",
    "\n",
    "# Read the existing CSV file, process it, and add new columns\n",
    "def process_csv(input_csv):\n",
    "    # Generate the output file name\n",
    "    output_csv = f\"{input_csv.split('.')[0]}_tokenized_by_{model_name}.csv\"\n",
    "    \n",
    "    with open(input_csv, 'r', encoding='utf-8') as infile, open(output_csv, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        fieldnames = reader.fieldnames + ['Tokens_Number', 'Tokens']  # Add new columns\n",
    "        writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "\n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Process each row and add new data\n",
    "        for row in reader:\n",
    "            word = row['Word']\n",
    "            num_tokens, tokens = tokenize_word(word)\n",
    "            row['Tokens_Number'] = num_tokens\n",
    "            row['Tokens'] = ' '.join(tokens)\n",
    "            writer.writerow(row)\n",
    "        print(f\"Processed file saved to: {output_csv}\")\n",
    "\n",
    "# Path to the CSV file\n",
    "input_csv = 'test_words.csv'  # Name of the original file\n",
    "\n",
    "# Execute the processing function\n",
    "process_csv(input_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
